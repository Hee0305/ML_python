{
 "cells": [
  {
   "cell_type": "raw",
   "id": "93ee04bd",
   "metadata": {},
   "source": [
    "# 문자 -> Vector // One-hot Encoding\n",
    "- 하나의 단어를 Vector의 Index로 인식, 단어 존재시 1, 없으면 0\n",
    "\n",
    "# Bag of words\n",
    "- 단어별로 인덱스를 부여해서, 한 문장(또는 문서)의 단어의 개수를 Vector로 표현\n",
    "\n",
    "# Distance measure \n",
    "    # Euclidian distance (L2 distance) \n",
    "    - 피타고라스 정리, 두 점 사이의 직선의 거리\n",
    "    - 데이터셋이 적을 경우 \n",
    "    # Cosine distance\n",
    "    - 두 점 사이의 각도 \n",
    "    - 데이터셋이 클 수록 유용하게 사용 \n",
    "    \n",
    "# Data set\n",
    "- 축구와 야구 선수들의 영문 기사를 분류해보자.\n",
    "- 1,2,3,4 : 야구 / 5,6,7,8 : 축구 \n",
    "    \n",
    "# Process\n",
    "1. 파일을 불러오기 \n",
    "2. 파일을 읽어서 단어사전 (corpus) 만들기 \n",
    "3. 단어별로 Index 만들기 \n",
    "4. 만들어진 인덱스로 문서별로 Bag of words vector 생성\n",
    "5. 비교하고자 하는 문서 비교하기 \n",
    "6. 얼마나 맞는지 측정하기 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839411bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 4024\n",
      "0.6950000000000001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def get_file_list(dir_name):\n",
    "    return os.listdir(dir_name)\n",
    "\n",
    "def get_conetents(file_list):\n",
    "    y_class = []\n",
    "    X_text = []\n",
    "    class_dict = {\n",
    "        1: \"0\", 2: \"0\", 3:\"0\", 4:\"0\", 5:\"1\", 6:\"1\", 7:\"1\", 8:\"1\"}\n",
    "\n",
    "    for file_name in file_list:\n",
    "        try:\n",
    "            f = open(file_name, \"r\",  encoding=\"cp949\")\n",
    "            category = int(file_name.split(os.sep)[1].split(\"_\")[0])\n",
    "            y_class.append(class_dict[category])\n",
    "            X_text.append(f.read())\n",
    "            f.close()\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(e)\n",
    "            print(file_name)\n",
    "    return X_text, y_class\n",
    "\n",
    "\n",
    "\n",
    "def get_cleaned_text(text):\n",
    "    import re\n",
    "    text = re.sub('\\W+','', text.lower() )\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_corpus_dict(text):\n",
    "    text = [sentence.split() for sentence in text]\n",
    "    clenad_words = [get_cleaned_text(word) for words in text for word in words]\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    corpus_dict = OrderedDict()\n",
    "    for i, v in enumerate(set(clenad_words)):\n",
    "        corpus_dict[v] = i\n",
    "    return corpus_dict\n",
    "\n",
    "\n",
    "def get_count_vector(text, corpus):\n",
    "    text = [sentence.split() for sentence in text]\n",
    "    word_number_list = [[corpus[get_cleaned_text(word)] for word in words] for words in text]\n",
    "    X_vector = [[0 for _ in range(len(corpus))] for x in range(len(text))]\n",
    "\n",
    "    for i, text in enumerate(word_number_list):\n",
    "        for word_number in text:\n",
    "            X_vector[i][word_number] += 1\n",
    "    return X_vector\n",
    "\n",
    "import math\n",
    "def get_cosine_similarity(v1,v2):\n",
    "    \"compute cosine similarity of v1 to v2: (v1 dot v2)/{||v1||*||v2||)\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "def get_similarity_score(X_vector, source):\n",
    "    source_vector = X_vector[source]\n",
    "    similarity_list = []\n",
    "    for target_vector in X_vector:\n",
    "        similarity_list.append(\n",
    "            get_cosine_similarity(source_vector, target_vector))\n",
    "    return similarity_list\n",
    "\n",
    "\n",
    "def get_top_n_similarity_news(similarity_score, n):\n",
    "    import operator\n",
    "    x = {i:v for i, v in enumerate(similarity_score)}\n",
    "    sorted_x = sorted(x.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    return list(reversed(sorted_x))[1:n+1]\n",
    "\n",
    "def get_accuracy(similarity_list, y_class, source_news):\n",
    "    source_class = y_class[source_news]\n",
    "\n",
    "    return sum([source_class == y_class[i[0]] for i in similarity_list]) / len(similarity_list)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dir_name = \"news_data\"\n",
    "    file_list = get_file_list(dir_name)\n",
    "    file_list = [os.path.join(dir_name, file_name) for file_name in file_list]\n",
    "\n",
    "    X_text, y_class = get_conetents(file_list)\n",
    "\n",
    "    corpus = get_corpus_dict(X_text)\n",
    "    print(\"Number of words : {0}\".format(len(corpus)))\n",
    "    X_vector = get_count_vector(X_text, corpus)\n",
    "    source_number = 10\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(80):\n",
    "        source_number = i\n",
    "\n",
    "        similarity_score = get_similarity_score(X_vector, source_number)\n",
    "        similarity_news = get_top_n_similarity_news(similarity_score, 10)\n",
    "        accuracy_score = get_accuracy(similarity_news, y_class, source_number)\n",
    "        result.append(accuracy_score)\n",
    "    print(sum(result) / 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
